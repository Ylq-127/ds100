{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Some common utilities for classwork and homework in Berkeley's Data100.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def head(filename, lines=5):\n",
    "    \"\"\"\n",
    "    Returns the first few lines of a file.\n",
    "    \n",
    "    filename: the name of the file to open\n",
    "    lines: the number of lines to include\n",
    "    \n",
    "    return: A list of the first few lines from the file.\n",
    "    \"\"\"\n",
    "    from itertools import islice\n",
    "    with open(filename, \"r\") as f:\n",
    "        return list(islice(f, lines))\n",
    "    \n",
    "\n",
    "def fetch_and_cache(data_url, file, data_dir=\"data\", force=False):\n",
    "    \"\"\"\n",
    "    Download and cache a url and return the file object.\n",
    "    \n",
    "    data_url: the web address to download\n",
    "    file: the file in which to save the results.\n",
    "    data_dir: (default=\"data\") the location to save the data\n",
    "    force: if true the file is always re-downloaded\n",
    "    \n",
    "    return: The pathlib.Path object representing the file.\n",
    "    \"\"\"\n",
    "\n",
    "    import requests\n",
    "    from hashlib import md5\n",
    "    from pathlib import Path\n",
    "    \n",
    "    data_dir = Path(data_dir)\n",
    "    data_dir.mkdir(exist_ok=True)\n",
    "    file_path = data_dir/Path(file)\n",
    "    # If the file already exists and we want to force a download then\n",
    "    # delete the file first so that the creation date is correct.\n",
    "    if force and file_path.exists():\n",
    "        file_path.unlink()\n",
    "    if force or not file_path.exists():\n",
    "        resp = requests.get(data_url, stream=True)\n",
    "        file_size = int(resp.headers.get('content-length', 0))\n",
    "        step = 40\n",
    "        chunk_size = file_size//step\n",
    "        with file_path.open('wb') as f:\n",
    "            for chunk in resp.iter_content(chunk_size): # write file in chunks\n",
    "                f.write(chunk)\n",
    "                step -= 1\n",
    "                print('[' + '#'*(41 - step) + (step)*' ' + ']\\r', end='')\n",
    "        print(f\"\\nDownloaded {data_url.split('/')[-1]}!\")\n",
    "    else:\n",
    "        import time\n",
    "        time_downloaded = time.ctime(file_path.stat().st_ctime)\n",
    "        print(\"Using version already downloaded:\", time_downloaded)\n",
    "    # Compute and print md5 hash of file, whether newly downloaded or not\n",
    "    m5 = md5()\n",
    "    m5.update(file_path.read_bytes())\n",
    "    print(f\"MD5 hash of file: {m5.hexdigest()}\")\n",
    "    return file_path\n",
    "\n",
    "\n",
    "def line_count(file):\n",
    "    \"\"\"\n",
    "    Computes the number of lines in a file.\n",
    "    \n",
    "    file: the file in which to count the lines.\n",
    "    return: The number of lines in the file\n",
    "    \"\"\"\n",
    "    with open(file, \"r\") as f:\n",
    "        return sum(1 for line in f)\n",
    "\n",
    "\n",
    "\n",
    "def fetch_and_cache_gdrive(gdrive_id, file, data_dir=\"data\", force=False):\n",
    "    \"\"\"\n",
    "    Download and cache a url and return the file object.\n",
    "    \n",
    "    data_url: the web address to download\n",
    "    file: the file in which to save the results.\n",
    "    data_dir: (default=\"data\") the location to save the data\n",
    "    force: if true the file is always re-downloaded\n",
    "    \n",
    "    return: The pathlib.Path object representing the file.\n",
    "    \"\"\"\n",
    "\n",
    "    import requests\n",
    "    from hashlib import md5\n",
    "    from pathlib import Path\n",
    "    \n",
    "    data_dir = Path(data_dir)\n",
    "    data_dir.mkdir(exist_ok=True)\n",
    "    file_path = data_dir/Path(file)\n",
    "    # If the file already exists and we want to force a download then\n",
    "    # delete the file first so that the creation date is correct.\n",
    "    if force and file_path.exists():\n",
    "        file_path.unlink()\n",
    "    if force or not file_path.exists():\n",
    "        download_file_from_google_drive(gdrive_id, file_path)\n",
    "    else:\n",
    "        import time\n",
    "        time_downloaded = time.ctime(file_path.stat().st_ctime)\n",
    "        print(\"Using version already downloaded:\", time_downloaded)\n",
    "    # Compute and print md5 hash of file, whether newly downloaded or not\n",
    "    m5 = md5()\n",
    "    m5.update(file_path.read_bytes())\n",
    "    print(f\"MD5 hash of file: {m5.hexdigest()}\")\n",
    "    return file_path\n",
    "\n",
    "    \n",
    "def download_file_from_google_drive(id, destination):\n",
    "    import requests\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "    session = requests.Session()\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "    save_response_content(response, destination)    \n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "    with open(destination, \"wb\") as f:\n",
    "        print(\"Downloading, this may take a few minutes.\")\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
